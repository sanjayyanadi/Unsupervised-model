{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "bqVZBxrvPD8n"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjayyanadi/Unsupervised-model/blob/main/unsupervised_books_recommendation_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  **Books Recommendation System**\n",
        "\n"
      ],
      "metadata": {
        "id": "ILM16xV1PD8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "bqVZBxrvPD8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS PROBLEM OVERVIEW**\n",
        "\n",
        "\n",
        "The traditional book ordering system is a manual and time-consuming process wherethe customer has to visit a bookstore to search and purchase the books. In this tightschedule, problems arise in finding specific books due to the inadequate distribution of books through the bookshop. The buyer could not get a recommendation for the correctselection of books."
      ],
      "metadata": {
        "id": "jivUA-ONOwse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries \n",
        "from google.colab import drive\n",
        "import operator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import math\n",
        "import re\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random\n",
        "from collections import Counter\n",
        "from scipy.sparse import csr_matrix\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset\n",
        "drive.mount('/content/drive/')  \n",
        "df_Books = pd.read_csv('/content/drive/MyDrive/ALMABETTER/CAPSTONE_PROJECT/un_supervised_learning_model/Books.csv')\n",
        "df_Users = pd.read_csv('/content/drive/MyDrive/ALMABETTER/CAPSTONE_PROJECT/un_supervised_learning_model/Users.csv')\n",
        "df_Ratings = pd.read_csv('/content/drive/MyDrive/ALMABETTER/CAPSTONE_PROJECT/un_supervised_learning_model/Ratings.csv')"
      ],
      "metadata": {
        "id": "CEhiayUv1809"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Books Dataset\n",
        "df_Books.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Users Dataset\n",
        "df_Users.head()"
      ],
      "metadata": {
        "id": "xYkUHl0DzVz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings Dataset\n",
        "df_Ratings.head()"
      ],
      "metadata": {
        "id": "dU20fnIqzViN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns \n",
        "# books\n",
        "print(\"books: \",df_Books.shape)\n",
        "# Users\n",
        "print(\"Users:\",df_Users.shape)\n",
        "# ratings\n",
        "print(\"ratings: \",df_Ratings.shape)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "# books\n",
        "print(\"Books:\")\n",
        "df_Books.info()\n",
        "#Users\n",
        "print(\"Users: \")\n",
        "df_Users.info()\n",
        "# Ratings\n",
        "print(\"Ratings: \")\n",
        "df_Ratings.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# books Dataset Duplicate Value Count\n",
        "len(df_Books[df_Books.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Users Dataset Duplicate Value Count\n",
        "len(df_Users[df_Users.duplicated()])"
      ],
      "metadata": {
        "id": "YomVO2Fv0gwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings Dataset Duplicate Value Count\n",
        "len(df_Ratings[df_Ratings.duplicated()])"
      ],
      "metadata": {
        "id": "eqBf0Yt60hfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Books\n",
        "# Missing Values/Null Values Count\n",
        "print(df_Books.isnull().sum())\n",
        "# Visualizing the missing values\n",
        "sns.heatmap(df_Books.isnull())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Users\n",
        "# Missing Values/Null Values Count\n",
        "print(df_Users.isnull().sum())\n",
        "# Visualizing the missing values\n",
        "sns.heatmap(df_Users.isnull())"
      ],
      "metadata": {
        "id": "Vprdnrem0gwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings\n",
        "# Missing Values/Null Values Count\n",
        "print(df_Ratings.isnull().sum())\n",
        "# Visualizing the missing values\n",
        "sns.heatmap(df_Ratings.isnull())"
      ],
      "metadata": {
        "id": "KgjcQQhE0hfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset given is a dataset from Telecommunication industry, and we have to analysis the churn of customers and the insights behind it.\n",
        "\n",
        "Churn prediction is analytical studies on the possibility of a customer abandoning a product or service. The goal is to understand and take steps to change it before the costumer gives up the product or service.\n",
        "\n",
        "The above dataset has 3333 rows and 20 columns. There are no mising values and duplicate values in the dataset. "
      ],
      "metadata": {
        "id": "Sobw8zmA0hfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "# Books\n",
        "print(\"books: \",df_Books.columns)\n",
        "#USers\n",
        "print(\"Users: \",df_Users.columns)\n",
        "# Ratings\n",
        "print(\"Ratings: \",df_Ratings.columns)"
      ],
      "metadata": {
        "id": "n87BaXA_42-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "print(df_Books.describe(include='all'))\n",
        "print(df_Users.describe(include='all'))\n",
        "print(df_Ratings.describe(include='all'))"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Book-Crossing dataset comprises 3 files.\n",
        "• Users\n",
        "Contains the users. Note that user IDs (User-ID) have been anonymized and map to integers. Demographic data is provided (Location, Age) if available. Otherwise, these fields contain NULL-values.\n",
        "\n",
        "• Books\n",
        "Books are identified by their respective ISBN. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given (Book-Title, Book-Author, Year-Of-Publication, Publisher), obtained from Amazon Web Services. Note that in case of several authors, only the first is provided. URLs linking to cover images are also given, appearing in three different flavours (Image-URL-S, Image-URL-M, Image-URL-L), i.e., small, medium, large. These URLs point to the Amazon web site.\n",
        "\n",
        "• Ratings\n",
        "Contains the book rating information. Ratings (Book-Rating) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df_Books.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df_Books[i].nunique(),\".\")\n",
        "for i in df_Users.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df_Users[i].nunique(),\".\")\n",
        "for i in df_Ratings.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df_Ratings[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## checking ISBN\n",
        "flag = 0\n",
        "k =[]\n",
        "reg = \"[^A-Za-z0-9]\"\n",
        "\n",
        "for x in df_Ratings['ISBN']:\n",
        "    z = re.search(reg,x)    \n",
        "    if z:\n",
        "        flag = 1\n",
        "\n",
        "if flag == 1:\n",
        "    print(\"False\")\n",
        "else:\n",
        "    print(\"True\")"
      ],
      "metadata": {
        "id": "o7zn5gKG29Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing extra characters from ISBN (from ratings dataset) existing in books dataset\n",
        "bookISBN = df_Books['ISBN'].tolist() \n",
        "reg = \"[^A-Za-z0-9]\" \n",
        "for index, row_Value in df_Ratings.iterrows():\n",
        "    z = re.search(reg, row_Value['ISBN'])    \n",
        "    if z:\n",
        "        f = re.sub(reg,\"\",row_Value['ISBN'])\n",
        "        if f in bookISBN:\n",
        "            df_Ratings.at[index , 'ISBN'] = f"
      ],
      "metadata": {
        "id": "Gz9wdf2Y4S09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Uppercasing all alphabets in ISBN\n",
        "df_Ratings['ISBN'] = df_Ratings['ISBN'].str.upper()"
      ],
      "metadata": {
        "id": "UNPvNhJA4-G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing null data from book author\n",
        "df_Books['Book-Author'].fillna(\"Unknown\" , inplace = True)\n",
        "df_Books['Book-Author'].isna().sum()"
      ],
      "metadata": {
        "id": "_FI9zmAvBauH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Books['Year-Of-Publication'].unique()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since year data has some object it it, we shall convert it into null data\n",
        "df_Books['Year-Of-Publication'] = pd.to_numeric(df_Books['Year-Of-Publication'],errors='coerce')\n",
        "df_Books['Year-Of-Publication'].isna().sum()\n",
        "#since year data has the year 0 and 2023 which is invalid, we shall convert it into null data\n",
        "df_Books.loc[(df_Books['Year-Of-Publication'] > 2023) | (df_Books['Year-Of-Publication'] == 0), 'year'] = 0\n",
        "#Replacing null data with median \n",
        "df_Books['Year-Of-Publication'].fillna(df_Books['year'].median() , inplace = True)\n",
        "df_Books['Year-Of-Publication'].isna().sum()\n",
        "df_Books['Year-Of-Publication']=df_Books['Year-Of-Publication'].astype(int)"
      ],
      "metadata": {
        "id": "7ONOI0rEAUeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing null data from publisher\n",
        "df_Books['Publisher'].fillna('other' , inplace = True)\n",
        "df_Books['Publisher'].isna().sum()"
      ],
      "metadata": {
        "id": "5ouY17t1BC2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(df_Users['Age'].unique()))"
      ],
      "metadata": {
        "id": "0ziu8YEVCou4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing age above 100 and below 10\n",
        "df_Users.loc[(df_Users['Age'] > 100) | (df_Users['Age'] < 10) , 'Age' ] = np.NAN\n",
        "#adding the maen data to the null data\n",
        "df_Users['Age'].fillna(df_Users['Age'].mean(), inplace = True)\n",
        "df_Users['Age'] = df_Users['Age'].astype(int)"
      ],
      "metadata": {
        "id": "MqVu2gjNCClN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop URL columns\n",
        "df_Books.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)\n",
        "df_Books.head()"
      ],
      "metadata": {
        "id": "T7QVFvzuvGqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging datasets\n",
        "df = pd.merge(df_Books, df_Ratings, on='ISBN', how='inner')\n",
        "df= pd.merge(df, df_Users, on='User-ID', how='inner')"
      ],
      "metadata": {
        "id": "VbhL8KdJYQJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.countplot(y=\"Book-Author\", data=df,order=df['Book-Author'].value_counts().index[0:10])\n",
        "plt.title(\"Top 10 books author\")"
      ],
      "metadata": {
        "id": "7KV3FIBzVdQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.countplot(y=\"Publisher\", data=df,order=df['Publisher'].value_counts().index[0:10])\n",
        "plt.title(\"Top 10 publishers\")"
      ],
      "metadata": {
        "id": "ofghYv3-bFSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.countplot(y=\"Book-Rating\", data=df,order=df['Book-Rating'].value_counts().index[0:10])\n",
        "plt.title(\"rating distributions\")"
      ],
      "metadata": {
        "id": "Kw-o4m6-oE6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Explicit Ratings\n",
        "plt.figure(figsize=(8,6))\n",
        "data = df[df['Book-Rating'] != 0]\n",
        "sns.countplot(x=\"Book-Rating\", data=data)\n",
        "plt.title(\"Explicit Ratings\")"
      ],
      "metadata": {
        "id": "3m-GYf2oqfYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "df.Age.hist(bins=[10*i for i in range(1, 10)])     \n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tHKU24Ygq0T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,6))\n",
        "sns.countplot(x=\"Location\", data=df,order=df['Location'].value_counts().index[0:10])\n",
        "plt.title(\"No of readers from each city (Top 10)\")"
      ],
      "metadata": {
        "id": "RsBF3jKgotzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.countplot(y=\"Book-Title\", data=df, order=df['Book-Title'].value_counts().index[0:10])\n",
        "plt.title(\"top 10 books with highest rating\")"
      ],
      "metadata": {
        "id": "qWc5wvUftZDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Books popular Yearly\n",
        "years = set()\n",
        "indices = []\n",
        "for ind, row in df.iterrows():\n",
        "    if row['Year-Of-Publication'] in years:\n",
        "        indices.append(ind)\n",
        "    else:\n",
        "        years.add(row['Year-Of-Publication'])\n",
        "\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "metadata": {
        "id": "MLQsRSwyxWBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Explicit Ratings Dataset\n",
        "dataset1 = df[df['Book-Rating'] != 0]\n",
        "dataset1 = dataset1.reset_index(drop = True)\n",
        "dataset1.shape"
      ],
      "metadata": {
        "id": "fAmakRM4bko5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Implicit Ratings Dataset\n",
        "dataset2 = df[df['Book-Rating'] == 0]\n",
        "dataset2 = dataset2.reset_index(drop = True)\n",
        "dataset2.shape"
      ],
      "metadata": {
        "id": "GmNLJPZPbked"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ***Popularity Based Filtering***\n",
        "As the name suggests Popularity based recommendation system works with the trend. It basically uses the items which are in trend right now. For example, if any book which is usually bought by every new user then there are chances that it may suggest that book to the user who just signed up.\n",
        "Book weighted avg formula:\n",
        "Weighted Rating(WR)=[vR/(v+m)]+[mC/(v+m)]\n",
        "where,\n",
        "v is the number of votes for the books;\n",
        "m is the minimum votes required to be listed in the chart;\n",
        "R is the average rating of the book; and\n",
        "C is the mean vote across the whole report.\n",
        "Now we find the values of v,m,R,C."
      ],
      "metadata": {
        "id": "Zh8rzhl4Q3l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def popular_books(df,n=200):\n",
        "    \n",
        "    rating_count = dataset1.groupby('Book-Title').count()['Book-Rating'].reset_index()    \n",
        "    rating_count.rename(columns={'Book-Rating':'Number_Of_Votes'},inplace=True)\n",
        "    \n",
        "    rating_avg = df.groupby('Book-Title')['Book-Rating'].mean().reset_index()    \n",
        "    rating_avg.rename(columns={'Book-Rating':'Ratings-Average'},inplace=True)\n",
        "    \n",
        "    popular_books = rating_count.merge(rating_avg,on='Book-Title')\n",
        "    \n",
        "    def weighted_rate(x):\n",
        "        v = x['Number_Of_Votes']\n",
        "        R = x['Ratings-Average']\n",
        "                \n",
        "        return ((v * R) + (m*C))/(v+m)\n",
        "    n = 10\n",
        "    C = popular_books['Ratings-Average'].mean()\n",
        "    m = popular_books['Number_Of_Votes'].quantile(0.95)\n",
        "    \n",
        "    # Filter out all qualified books into a new DataFrame\n",
        "    popular_books = popular_books[popular_books['Number_Of_Votes'] >= m]\n",
        "    \n",
        "    popular_books['Polularity-Score'] = popular_books.apply(weighted_rate,axis=1)\n",
        "    \n",
        "    popular_books = popular_books.sort_values(by='Polularity-Score',ascending=False)\n",
        "    print(\"Top {} popular books\".format(n))\n",
        "    return popular_books[['Book-Title','Ratings-Average','Number_Of_Votes','Polularity-Score']].reset_index(drop=True).head(n)\n",
        "    display(popular_books(df,10))\n",
        "\n",
        "n =10\n",
        "print(\"Top {} popular books\".format(n))\n",
        "display(popular_books(dataset1,10))"
      ],
      "metadata": {
        "id": "iAy2DscxvBJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***recommendations of books based on same author and  publisher of given book name***"
      ],
      "metadata": {
        "id": "PGMu3R6PkVi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recom_author_public():\n",
        "    bookName= input(\"name a book for recommendations based on authors\")\n",
        "    number=int(input(\"enter a number recommendations required\"))\n",
        "    if bookName in list(dataset1['Book-Title'].unique()):\n",
        "        d = dataset1[dataset1['Book-Title'] == bookName]\n",
        "        # book Author\n",
        "        print(\"\\nBooks by same Author:\\n\")\n",
        "        au = d['Book-Author'].unique()\n",
        "        data = dataset1[dataset1['Book-Title'] != bookName]\n",
        "        if au[0] in list(data['Book-Author'].unique()):\n",
        "            k2 = data[data['Book-Author'] == au[0]]\n",
        "        k2 = k2.sort_values(by=['Book-Rating'])\n",
        "        z = k2['Book-Title'].unique()\n",
        "        for x in range(len(z)):\n",
        "            print(z[x])\n",
        "            if x >= number-1:\n",
        "                break\n",
        "        # book publisher\n",
        "        print(\"\\n\\nBooks by same Publisher:\\n\")\n",
        "        au = d['Publisher'].unique()\n",
        "        \n",
        "        if au[0] in list(data['Publisher'].unique()):\n",
        "            k2 = pd.DataFrame(data[data['Publisher'] == au[0]])\n",
        "        k2=k2.sort_values(by=['Book-Rating']) \n",
        "        z = k2['Book-Title'].unique()\n",
        "        for x in range(len(z)):\n",
        "            print(z[x])\n",
        "            if x >= number-1:\n",
        "                break\n",
        "    else:\n",
        "        print(\"Invalid Book Name!!\")"
      ],
      "metadata": {
        "id": "uwOOkU5lmRHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recom_author_public()"
      ],
      "metadata": {
        "id": "6Fz2WpERmTgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Collaborative Filtering based Recommendation System--(Item-Item Based)***"
      ],
      "metadata": {
        "id": "zfJbLWVwRXG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bookName = input(\"Enter a book name: \")\n",
        "number = int(input(\"Enter number of books to recommend: \"))"
      ],
      "metadata": {
        "id": "fYJ5FG6srRQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dataset1['Book-Title'].value_counts())\n",
        "df['Total-Ratings'] = df['Book-Title']\n",
        "df['Book-Title'] = df.index\n",
        "df.reset_index(level=0, inplace=True)\n",
        "df = df.drop('index',axis=1)\n",
        "\n",
        "df = dataset1.merge(df, left_on = 'Book-Title', right_on = 'Book-Title', how = 'left')\n",
        "df = df.drop(['Year-Of-Publication','Publisher','Age'], axis=1)\n",
        "\n",
        "popularity_threshold = 50\n",
        "popular_book = df[df['Total-Ratings'] >= popularity_threshold]\n",
        "popular_book = popular_book.reset_index(drop = True)"
      ],
      "metadata": {
        "id": "NDENOxvdmlaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf = pd.DataFrame()\n",
        "testdf['ISBN'] = popular_book['ISBN']\n",
        "testdf['Book-Rating'] = popular_book['Book-Rating']\n",
        "testdf['User-ID'] = popular_book['User-ID']\n",
        "testdf = testdf[['User-ID','Book-Rating']].groupby(testdf['ISBN'])"
      ],
      "metadata": {
        "id": "_j___bJCmnZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listOfDictonaries=[]\n",
        "indexMap = {}\n",
        "reverseIndexMap = {}\n",
        "ptr=0\n",
        "\n",
        "for groupKey in testdf.groups.keys():\n",
        "    tempDict={}\n",
        "    groupDF = testdf.get_group(groupKey)\n",
        "    for i in range(0,len(groupDF)):\n",
        "        tempDict[groupDF.iloc[i,0]] = groupDF.iloc[i,1]\n",
        "    indexMap[ptr]=groupKey\n",
        "    reverseIndexMap[groupKey] = ptr\n",
        "    ptr=ptr+1\n",
        "    listOfDictonaries.append(tempDict)\n",
        "\n",
        "dictVectorizer = DictVectorizer(sparse=True)\n",
        "vector = dictVectorizer.fit_transform(listOfDictonaries)\n",
        "pairwiseSimilarity = cosine_similarity(vector)"
      ],
      "metadata": {
        "id": "r8leGkKcqQyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printBookDetails(bookID):\n",
        "    print(dataset1[dataset1['ISBN']==bookID]['Book-Title'].values[0])\n",
        "\n",
        "def getTopRecommandations(bookID):\n",
        "    bookName= input(\"input a book name for recommendations \")\n",
        "    number= input(\"input a number for number of recommendations \")\n",
        "    collaborative = []\n",
        "    row = reverseIndexMap[bookID]\n",
        "    print(\"Input Book:\")\n",
        "    printBookDetails(bookID)\n",
        "    \n",
        "    print(\"\\nRECOMMENDATIONS:\\n\")\n",
        "    \n",
        "    mn = 0\n",
        "    similar = []\n",
        "    for i in np.argsort(pairwiseSimilarity[row])[:-2][::-1]:\n",
        "          if dataset1[dataset1['ISBN']==indexMap[i]]['Book-Title'].values[0] not in similar:\n",
        "                if int(mn)>=int(number):\n",
        "                      break\n",
        "                mn+=1\n",
        "                similar.append(dataset1[dataset1['ISBN']==indexMap[i]]['Book-Title'].values[0])\n",
        "                printBookDetails(indexMap[i])\n",
        "                collaborative.append(dataset1[dataset1['ISBN']==indexMap[i]]['Book-Title'].values[0])\n",
        "    return collaborative\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "3DFkF9SwoHWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = list(dataset1['Book-Title'])\n",
        "m = list(dataset1['ISBN'])\n",
        "\n",
        "collaborative = getTopRecommandations(m[k.index(bookName)])"
      ],
      "metadata": {
        "id": "YMDqCuUuq8wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bSNeK10ksb3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "popularity_threshold = 50\n",
        "\n",
        "user_count = dataset1['User-ID'].value_counts()\n",
        "data = dataset1[dataset1['User-ID'].isin(user_count[user_count >= popularity_threshold].index)]\n",
        "rat_count = data['Book-Rating'].value_counts()\n",
        "data = data[data['Book-Rating'].isin(rat_count[rat_count >= popularity_threshold].index)]\n",
        "\n",
        "matrix = data.pivot_table(index='User-ID', columns='ISBN', values = 'Book-Rating').fillna(0)"
      ],
      "metadata": {
        "id": "g1fPV5l_kO8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_rating = pd.DataFrame(dataset1.groupby('ISBN')['Book-Rating'].mean())\n",
        "average_rating['ratingCount'] = pd.DataFrame(df_Ratings.groupby('ISBN')['Book-Rating'].count())\n",
        "average_rating.sort_values('ratingCount', ascending=False).head()"
      ],
      "metadata": {
        "id": "uuSGNh9CkO5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "isbn = df_Books.loc[df_Books['Book-Title'] == bookName].reset_index(drop = True).iloc[0]['ISBN']\n",
        "row = matrix[isbn]\n",
        "correlation = pd.DataFrame(matrix.corrwith(row), columns = ['Pearson Corr'])\n",
        "corr = correlation.join(average_rating['ratingCount'])\n",
        "\n",
        "res = corr.sort_values('Pearson Corr', ascending=False).head(number+1)[1:].index\n",
        "corr_books = pd.merge(pd.DataFrame(res, columns = ['ISBN']), df_Books, on='ISBN')\n",
        "print(\"\\n Recommended Books: \\n\")\n",
        "corr_books"
      ],
      "metadata": {
        "id": "-gKSDmPgkO2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OEy-usWwsl3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = (dataset1.groupby(by = ['Book-Title'])['Book-Rating'].count().reset_index().\n",
        "        rename(columns = {'Book-Rating': 'Total-Rating'})[['Book-Title', 'Total-Rating']])\n",
        "\n",
        "result = pd.merge(data, dataset1, on='Book-Title')\n",
        "result = result[result['Total-Rating'] >= popularity_threshold]\n",
        "result = result.reset_index(drop = True)\n",
        "\n",
        "matrix = result.pivot_table(index = 'Book-Title', columns = 'User-ID', values = 'Book-Rating').fillna(0)\n",
        "up_matrix = csr_matrix(matrix)"
      ],
      "metadata": {
        "id": "bjGkbXGVkOzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\n",
        "model.fit(up_matrix)\n",
        "\n",
        "distances, indices = model.kneighbors(matrix.loc[bookName].values.reshape(1, -1), n_neighbors = number+1)\n",
        "print(\"\\nRecommended books:\\n\")\n",
        "for i in range(0, len(distances.flatten())):\n",
        "    if i > 0:\n",
        "        print(matrix.index[indices.flatten()[i]]) "
      ],
      "metadata": {
        "id": "__I6V5fBzF66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recom_knneighbor():\n",
        "    data = (dataset1.groupby(by = ['Book-Title'])['Book-Rating'].count().reset_index().\n",
        "        rename(columns = {'Book-Rating': 'Total-Rating'})[['Book-Title', 'Total-Rating']])\n",
        "\n",
        "    result = pd.merge(data, dataset1, on='Book-Title')\n",
        "    result = result[result['Total-Rating'] >= popularity_threshold]\n",
        "    result = result.reset_index(drop = True)\n",
        "\n",
        "    matrix = result.pivot_table(index = 'Book-Title', columns = 'User-ID', values = 'Book-Rating').fillna(0)\n",
        "    up_matrix = csr_matrix(matrix)\n",
        "    model = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\n",
        "    model.fit(up_matrix)\n",
        "\n",
        "    distances, indices = model.kneighbors(matrix.loc[bookName].values.reshape(1, -1), n_neighbors = number+1)\n",
        "    print(\"\\nRecommended books:\\n\")\n",
        "    for i in range(0, len(distances.flatten())):\n",
        "        if i > 0:\n",
        "            print(matrix.index[indices.flatten()[i]])"
      ],
      "metadata": {
        "id": "ZMluqZGuzF4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recom_knneighbor()"
      ],
      "metadata": {
        "id": "vlx2YCJys4nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PQ1abHpRtHYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "popularity_threshold = 80\n",
        "popular_book = df[df['Total-Ratings'] >= popularity_threshold]\n",
        "popular_book = popular_book.reset_index(drop = True)\n",
        "popular_book.shape"
      ],
      "metadata": {
        "id": "nuK7Wvi_tFST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf = TfidfVectorizer(ngram_range=(1, 2), min_df = 1, stop_words='english')\n",
        "tfidf_matrix = tf.fit_transform(popular_book['Book-Title'])\n",
        "tfidf_matrix.shape"
      ],
      "metadata": {
        "id": "TvQE4MCXtLOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_df = tfidf_matrix.astype(np.float32)\n",
        "cosine_similarities = cosine_similarity(normalized_df, normalized_df)\n",
        "cosine_similarities.shape"
      ],
      "metadata": {
        "id": "XizfTai0tNQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recommended Books:\\n\")\n",
        "isbn = df_Books.loc[df_Books['Book-Title'] == bookName].reset_index(drop = True).iloc[0]['ISBN']\n",
        "content = []\n",
        "\n",
        "idx = popular_book.index[popular_book['ISBN'] == isbn].tolist()[0]\n",
        "similar_indices = cosine_similarities[idx].argsort()[::-1]\n",
        "similar_items = []\n",
        "for i in similar_indices:\n",
        "    if popular_book['Book-Title'][i] != bookName and popular_book['Book-Title'][i] not in similar_items and len(similar_items) < number:\n",
        "        similar_items.append(popular_book['Book-Title'][i])\n",
        "        content.append(popular_book['Book-Title'][i])\n",
        "\n",
        "for book in similar_items:\n",
        "    print(book)"
      ],
      "metadata": {
        "id": "5eJ-PRKXtPhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = list()\n",
        "k = float(1/number)\n",
        "for x in range(number):\n",
        "      z.append(1-k*x)\n",
        "\n",
        "dictISBN = {}\n",
        "for x in collaborative:\n",
        "      dictISBN[x] = z[collaborative.index(x)]\n",
        "\n",
        "for x in content:\n",
        "    if x not in dictISBN:\n",
        "        dictISBN[x] = z[content.index(x)]\n",
        "    else:\n",
        "        dictISBN[x] += z[content.index(x)]\n",
        "\n",
        "ISBN = dict(sorted(dictISBN.items(),key=operator.itemgetter(1),reverse=True))\n",
        "w=0\n",
        "print(\"Input Book:\\n\")\n",
        "print(bookName)\n",
        "print(\"\\nRecommended Books:\\n\")\n",
        "for x in ISBN.keys():\n",
        "    if w>=number:\n",
        "        break\n",
        "    w+=1\n",
        "    print(x)"
      ],
      "metadata": {
        "id": "8nkcyXa4txr4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}